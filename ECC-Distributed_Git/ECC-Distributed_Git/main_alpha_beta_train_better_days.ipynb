{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import NetworkedRENs, REN, RNNModel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import os\n",
    "\n",
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
    "from os.path import dirname, join as pjoin\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data\n",
    "folderpath = os.getcwd()\n",
    "filepath = pjoin(folderpath, 'input_3.mat')#'dataset_sysID_3tanks.mat')\n",
    "data_in = scipy.io.loadmat(filepath)\n",
    "filepath = pjoin(folderpath, 'output_Q_3.mat')\n",
    "data_out = scipy.io.loadmat(filepath)\n",
    "filepath = pjoin(folderpath, 'subsystems.mat')\n",
    "data_sub = scipy.io.loadmat(filepath)\n",
    "\n",
    "filepath = pjoin(folderpath, 'denormalize.mat')\n",
    "data_max = scipy.io.loadmat(filepath)\n",
    "\n",
    "# Extract data from dictionary\n",
    "maxTrit, maxTdel = data_max['maxTrit'], data_max['maxTman']\n",
    "Toutass_t, Toutass_v, Toutchill_t, Toutchill_v = data_sub['Toutass_train'], data_sub['Toutass_val'], data_sub['Toutchillers_train'], data_sub['Toutchillers_val']\n",
    "dExp, yExp, dExp_val, yExp_val, time__, buildtot, buildtot_val = data_in['dExp'], data_out['yExp'], \\\n",
    "    data_in['dExp_val'], data_out['yExp_val'], data_in['time__'], data_out['buildtotnorm'], data_out['buildtotnorm_val']\n",
    "nExp = yExp.size\n",
    "\n",
    "t = time__\n",
    "\n",
    "t_end = t.size\n",
    "\n",
    "#initialize the model\n",
    "\n",
    "ny = np.shape(yExp[0,-1])[1]\n",
    "nd = np.shape(dExp[0,-1])[1]\n",
    "\n",
    "#t = np.arange(0, np.size(dExp[0, 0], 1) * Ts-Ts, Ts)\n",
    "#t_end = yExp[0, 0].shape[1] - 1\n",
    "\n",
    "for exp in range(nExp):\n",
    "    y_exp = yExp[0,exp]\n",
    "    d_exp = dExp[0,exp]\n",
    "    plt.figure(figsize=(4 * 2, 4))\n",
    "    for out in range(ny):\n",
    "        plt.subplot(2, 2, out+1)\n",
    "        plt.plot(t[14000:16500], y_exp[14000:16500,out])\n",
    "        plt.title(r\"Water level h%i \"%out + r\"in experiment %i\"%(exp+1))\n",
    "    plt.subplot(2, 2, ny+1)\n",
    "    plt.plot(t[14000:16500], d_exp[14000:16500,1])\n",
    "    plt.title(r\"v in experiment %i\"%(exp+1))\n",
    "    # set the spacing between subplots\n",
    "    plt.subplots_adjust(left=0.1,\n",
    "                        bottom=0.1, \n",
    "                        right=0.9, \n",
    "                        top=0.9, \n",
    "                        wspace=0.4, \n",
    "                        hspace=0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN OF NETWORKED RENs\n",
    "epochs = 150\n",
    "t_end = 2500\n",
    "\n",
    "torch.manual_seed(2)\n",
    "N = 3 # Number of interconnected systems\n",
    "\n",
    "n = torch.tensor([2, 2, 2])  # input dimensions\n",
    "p = torch.tensor([1, 1, 1])  # output dimensions\n",
    "\n",
    "n_xi = np.array([5, 5, 5]) # nel paper n1, numero di stati\n",
    "l = np.array([5, 5, 5])  # nel paper q, dimension of the square matrix D11 -- number of _non-linear layers_ of the RE\n",
    "\n",
    "#alpha = 0.6\n",
    "#beta = 0.4\n",
    "\n",
    "#Muy = torch.cat((torch.tensor([[0, alpha, beta], [1, 0, 0], [1, 0, 0]]), torch.zeros(3,3)), dim=0)\n",
    "#Muy = Muy.float()\n",
    "\n",
    "Mud = torch.cat((torch.zeros(3,3), torch.eye(3)), dim=0)\n",
    "#Mey = torch.tensor([[0, alpha, beta], [1, 0, 0]])\n",
    "\n",
    "# Define the system\n",
    "RENsys = NetworkedRENs(N, Mud, n, p, n_xi, l)\n",
    "\n",
    "# Define Loss function\n",
    "MSE = nn.MSELoss()\n",
    "\n",
    "# Define Optimization method\n",
    "learning_rate = 1.0e-1\n",
    "optimizer = torch.optim.Adam(RENsys.parameters(), lr=learning_rate)\n",
    "optimizer.zero_grad()\n",
    "\n",
    "LOSS = np.zeros(epochs)\n",
    "loss = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    if epoch == epochs - epochs / 2:\n",
    "        learning_rate = 1.0e-2\n",
    "        optimizer = torch.optim.Adam(RENsys.parameters(), lr=learning_rate)\n",
    "    if epoch == epochs - epochs / 6:\n",
    "        learning_rate = 1.0e-3\n",
    "        optimizer = torch.optim.Adam(RENsys.parameters(), lr=learning_rate)\n",
    "    optimizer.zero_grad()\n",
    "    loss = 0\n",
    "    for exp in range(nExp - 1):\n",
    "        xi = []\n",
    "        y = torch.cat((torch.from_numpy(yExp[0, exp][14000:16500,0]).float().to(device).unsqueeze(1),\n",
    "                       torch.from_numpy(Toutass_t[exp*30240 +14000:exp*30240 + 16500]).float().to(device),\n",
    "                       torch.from_numpy(Toutchill_t[exp*30240 +14000:exp*30240 + 16500]).float().to(device)), dim=1)\n",
    "        y = y.T\n",
    "        yRENm = torch.randn(3,t_end , device=device, dtype=dtype)\n",
    "        yRENm[0,:] = y[0,:]\n",
    "        for j in range(N):\n",
    "            xi.append(torch.randn(RENsys.r[j].n, device=device, dtype=dtype))\n",
    "        d = torch.cat((torch.from_numpy(buildtot[exp*30240 +14000:exp*30240 + 16500]).float().to(device),\n",
    "                       torch.from_numpy(dExp[0, exp][14000:16500,-1]).float().to(device).unsqueeze(1),\n",
    "                       torch.from_numpy(dExp[0, exp][14000:16500,-2]).float().to(device).unsqueeze(1)), dim=1)\n",
    "        d = d.T\n",
    "        xi = torch.cat(xi)\n",
    "        for t in range(1, t_end):\n",
    "            yRENm[:, t], xi = RENsys(t, d[:, t - 1], xi)\n",
    "\n",
    "        loss = loss + MSE(yRENm[:, 0:yRENm.size(1)], y[:, 0:t_end + 1])\n",
    "        # ignorare da loss effetto condizione iniziale\n",
    "\n",
    "    loss = loss / nExp\n",
    "    loss.backward()\n",
    "    # loss.backward(retain_graph=True)\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"Epoch: {epoch + 1} \\t||\\t Loss: {loss}\")\n",
    "    for net in range(N):\n",
    "        print(f\"L2 gain REN%i\"%net+\":%.1f\"%RENsys.r[net].gamma)\n",
    "    LOSS[epoch] = loss\n",
    "    \n",
    "    # Or save a checkpoint with optimizer and other details\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': RENsys.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "    }, f'better_epoch_{epoch+1}.pth')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Load \n",
    "checkpoint = torch.load('checkpoint_epoch_218.pth')\n",
    "\n",
    "t_end = 2500\n",
    "nExp = 1\n",
    "\n",
    "N = 3 # Number of interconnected systems\n",
    "\n",
    "n = torch.tensor([2, 2, 2])  # input dimensions\n",
    "p = torch.tensor([1, 1, 1])  # output dimensions\n",
    "\n",
    "n_xi = np.array([5, 5, 5]) # nel paper n1, numero di stati\n",
    "l = np.array([5, 5, 5])  # nel paper q, dimension of the square matrix D11 -- number of _non-linear layers_ of the RE\n",
    "\n",
    "alpha = 0.6\n",
    "beta = 0.4\n",
    "\n",
    "Muy = torch.cat((torch.tensor([[0, alpha, beta], [1, 0, 0], [1, 0, 0]]), torch.zeros(3,3)), dim=0)\n",
    "Muy = Muy.float()\n",
    "\n",
    "Mud = torch.cat((torch.zeros(3,3), torch.eye(3)), dim=0)\n",
    "Mey = torch.tensor([[0, alpha, beta], [1, 0, 0]])\n",
    "\n",
    "# Define the system\n",
    "RENsys = NetworkedRENs(N, Muy, Mud, Mey, n, p, n_xi, l)\n",
    "\n",
    "# Define Loss function\n",
    "MSE = nn.MSELoss()\n",
    "# Restore the model state\n",
    "RENsys.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# If needed, restore the optimizer state (for resuming training)\n",
    "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "# Retrieve the last epoch and loss\n",
    "last_epoch = checkpoint['epoch']\n",
    "last_loss = checkpoint['loss']\n",
    "\n",
    "print(f\"Resuming from Epoch {last_epoch + 1} with Loss: {last_loss}\")\n",
    "\n",
    "# Ensure the model is in evaluation mode for validation\n",
    "RENsys.eval()\n",
    "\n",
    "# Perform validation\n",
    "with torch.no_grad():\n",
    "    validation_loss = 0\n",
    "    for exp in range(nExp - 1):\n",
    "        xi = []\n",
    "        yval = torch.cat((torch.from_numpy(yExp_val[0, exp][14000:16500, 0]).float().to(device).unsqueeze(1),\n",
    "                       torch.from_numpy(Toutass_v[exp * 30240 + 14000:exp * 30240 + 16500]).float().to(device),\n",
    "                       torch.from_numpy(Toutchill_v[exp * 30240 + 14000:exp * 30240 + 16500]).float().to(device)), dim=1)\n",
    "        yval = yval.T\n",
    "        yRENm_val = torch.randn(3, t_end, device=device, dtype=torch.float)\n",
    "        yRENm_val[0, :] = yval[0, :]\n",
    "        \n",
    "        for j in range(N):\n",
    "            xi.append(torch.randn(RENsys.r[j].in_features, device=device, dtype=torch.float))\n",
    "            \n",
    "        dval = torch.cat((torch.from_numpy(buildtot_val[exp * 30240 + 14000:exp * 30240 + 16500]).float().to(device),\n",
    "                       torch.from_numpy(dExp_val[0, exp][14000:16500, -1]).float().to(device).unsqueeze(1),\n",
    "                       torch.from_numpy(dExp_val[0, exp][14000:16500, -2]).float().to(device).unsqueeze(1)), dim=1)\n",
    "        dval = dval.T\n",
    "        xi = torch.cat(xi)\n",
    "        \n",
    "        for t in range(1, t_end):\n",
    "            yRENm_val[:, t], xi = RENsys(t, dval[:, t - 1], xi)\n",
    "\n",
    "        validation_loss += MSE(yRENm_val[:, 0:yRENm_val.size(1)], yval[:, 0:t_end + 1])\n",
    "\n",
    "    validation_loss = validation_loss / nExp\n",
    "    print(f\"Validation Loss: {validation_loss}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
